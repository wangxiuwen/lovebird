import asyncio
import os
import edge_tts
import time
import requests
import json
import random
from datetime import datetime
from openai import OpenAI  # ä½¿ç”¨ OpenAI åŒ…å…¼å®¹é˜¿é‡Œ LLM
from config import ConfigLoader
from pydub import AudioSegment
from scipy.io.wavfile import read
import sounddevice as sd
import numpy as np

cfg = ConfigLoader().config

# é…ç½®
BASE_DIR = "./"
WORD_LIST_FILE = os.path.join(BASE_DIR, "word_list.txt")  # å•è¯åˆ—è¡¨æ–‡ä»¶
OUTPUT_AUDIO_FILE_EN = os.path.join(BASE_DIR, "word_audio_en.mp3")  # è‹±æ–‡éŸ³é¢‘æ–‡ä»¶
OUTPUT_AUDIO_FILE_CN = os.path.join(BASE_DIR, "word_audio_cn.mp3")  # ä¸­æ–‡éŸ³é¢‘æ–‡ä»¶

# è¯­éŸ³è®¾ç½®
VOICE_EN = "en-US-JennyNeural"  # è‹±æ–‡å¥³å£°
VOICE_CN = "zh-CN-XiaoxiaoNeural"  # ä¸­æ–‡å¥³å£°
SPEECH_RATE_EN = "-20%"  # è‹±æ–‡é™ä½ 20% è¯­é€Ÿ
SPEECH_RATE_CN = "+0%"  # ä¸­æ–‡ä¿æŒé»˜è®¤è¯­é€Ÿ

# æ˜¯å¦ä½¿ç”¨ Ollamaï¼ˆFalse è¡¨ç¤ºä½¿ç”¨é˜¿é‡Œ LLMï¼‰
USE_OLLAMA = False

# Ollama API é…ç½®
OLLAMA_URL = "http://localhost:11434/api/generate"
TIMEOUT = 180  # è¶…æ—¶æ—¶é—´

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆç”¨äºé˜¿é‡Œ LLMï¼‰
def init_openai_client():
    return OpenAI(
        api_key=cfg.llm.api_key,
        base_url=cfg.llm.base_url,
    )

# ä»æ–‡ä»¶ä¸­è¯»å–å•è¯å¹¶éšæœºæ‰“ä¹±
def load_words(file_path):
    if not os.path.exists(file_path):
        print(f"å•è¯æ–‡ä»¶ {file_path} ä¸å­˜åœ¨ï¼")
        return []

    with open(file_path, "r", encoding="utf-8") as f:
        words = [line.strip() for line in f if line.strip()]
    random.shuffle(words)  # éšæœºæ‰“ä¹±å•è¯åˆ—è¡¨
    return words

# è°ƒç”¨ Ollama è·å–å•è¯ä¿¡æ¯
def call_ollama(prompt):
    payload = {
        "model": "qwen2.5:0.5b",
        "prompt": prompt,
        "stream": False,
        "temperature": 0.8,
    }
    try:
        response = requests.post(OLLAMA_URL, json=payload, timeout=TIMEOUT)
        response.raise_for_status()
        data = response.json()
        return data.get("response", "").strip()
    except Exception as e:
        print(f"Ollama è¯·æ±‚é”™è¯¯ï¼š{e}")
        return None

# è°ƒç”¨é˜¿é‡Œ LLM è·å–å•è¯ä¿¡æ¯
def call_ali_llm(prompt):
    try:
        client = init_openai_client()
        response = client.chat.completions.create(
            model=cfg.llm.model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè¯­è¨€å­¦ä¹ åŠ©æ‰‹ï¼Œæä¾›å‡†ç¡®çš„å•è¯é‡Šä¹‰å’Œä¾‹å¥ã€‚"},
                {"role": "user", "content": prompt},
            ],
            temperature=0.8,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"é˜¿é‡Œ LLM è¯·æ±‚é”™è¯¯ï¼š{e}")
        return None

# è·å–å•è¯çš„è‹±æ–‡ã€ä¸­æ–‡é‡Šä¹‰å’Œä¾‹å¥
def get_word_info(word):
    prompt = (
        f"è¯·ä¸ºå•è¯ '{word}' æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š\n"
        f"1. è‹±æ–‡å•è¯\n"
        f"2. è‹±æ–‡å­—æ¯æ‹¼è¯»ï¼ˆå¦‚ C A Tï¼‰\n"
        f"3. ä¸­æ–‡é‡Šä¹‰ï¼ˆç®€æ´æ˜äº†ï¼‰\n"
        f"4. ä¸€ä¸ªç®€çŸ­çš„è‹±æ–‡ä¾‹å¥ï¼ˆä¸è¶…è¿‡15ä¸ªå•è¯ï¼‰\n"
        f"5. è¯¥ä¾‹å¥çš„ä¸­æ–‡ç¿»è¯‘\n"
        f"è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼ˆç›´æ¥è¾“å‡ºå†…å®¹ï¼Œä¸è¦å¤šä½™è§£é‡Šï¼‰ï¼š\n"
        f"English: [è‹±æ–‡å•è¯]\n"
        f"Spelling: [å­—æ¯æ‹¼è¯»]\n"
        f"Chinese: [ä¸­æ–‡é‡Šä¹‰]\n"
        f"Example: [è‹±æ–‡ä¾‹å¥]\n"
        f"Translation: [ä¸­æ–‡ç¿»è¯‘]"
    )

    if USE_OLLAMA:
        response = call_ollama(prompt)
    else:
        response = call_ali_llm(prompt)

    if not response:
        return None

    try:
        lines = response.split("\n")
        info = {}
        for line in lines:
            if line.startswith("English:"):
                info["english"] = line.replace("English:", "").strip()
            elif line.startswith("Spelling:"):
                info["spelling"] = line.replace("Spelling:", "").strip()
            elif line.startswith("Chinese:"):
                info["chinese"] = line.replace("Chinese:", "").strip()
            elif line.startswith("Example:"):
                info["example"] = line.replace("Example:", "").strip()
            elif line.startswith("Translation:"):
                info["translation"] = line.replace("Translation:", "").strip()
        return info
    except Exception as e:
        print(f"è§£æå•è¯ä¿¡æ¯å¤±è´¥ï¼š{e}")
        return None

# ä½¿ç”¨ edge-tts ç”ŸæˆéŸ³é¢‘
async def generate_audio(text, voice, rate, output_file):
    try:
        communicate = edge_tts.Communicate(text, voice, rate=rate)
        await communicate.save(output_file)
        return True
    except Exception as e:
        print(f"ç”ŸæˆéŸ³é¢‘å¤±è´¥ï¼š{e}")
        return False

# æ’­æ”¾éŸ³é¢‘ (ä½¿ç”¨ sounddevice å’Œ numpy)
def play_audio(file_path):
    if not os.path.exists(file_path):
        print(f"éŸ³é¢‘æ–‡ä»¶æœªæ‰¾åˆ°ï¼š{file_path}")
        return

    # å°† MP3 æ–‡ä»¶è½¬æ¢ä¸º WAV æ ¼å¼
    wav_file = file_path.replace(".mp3", ".wav")
    audio = AudioSegment.from_file(file_path, format="mp3")
    audio.export(wav_file, format="wav")

    # ä½¿ç”¨ sounddevice æ’­æ”¾ WAV æ–‡ä»¶
    sample_rate, data = read(wav_file)
    sd.play(data, sample_rate)
    sd.wait()

    # åˆ é™¤ä¸´æ—¶ WAV æ–‡ä»¶
    os.remove(wav_file)

# ä¸»å‡½æ•°
async def main():
    words = load_words(WORD_LIST_FILE)
    if not words:
        print("æ²¡æœ‰åŠ è½½åˆ°å•è¯ï¼Œç¨‹åºé€€å‡ºã€‚")
        return

    print(f"å…±åŠ è½½ {len(words)} ä¸ªå•è¯ï¼Œå¼€å§‹éšæœºæ’­æ”¾...")

    for i, word in enumerate(words, 1):
        print(f"\nğŸ“– ç¬¬ {i}/{len(words)} ä¸ªå•è¯ï¼š{word}")

        word_info = get_word_info(word)
        if not word_info:
            print(f"æ— æ³•è·å– {word} çš„ä¿¡æ¯ï¼Œè·³è¿‡ã€‚")
            continue

        print(f"English: {word_info['english']}")
        print(f"Spelling: {word_info['spelling']}")
        print(f"Chinese: {word_info['chinese']}")
        print(f"Example: {word_info['example']}")
        print(f"Translation: {word_info['translation']}")

        full_english_text = f"{word_info['spelling']}. {word_info['english']}. {word_info['example']}"
        full_chinese_text = f"{word_info['chinese']}. {word_info['translation']}"

        print("ç”Ÿæˆè‹±æ–‡éŸ³é¢‘...")
        await generate_audio(full_english_text, VOICE_EN, SPEECH_RATE_EN, OUTPUT_AUDIO_FILE_EN)

        print("ç”Ÿæˆä¸­æ–‡éŸ³é¢‘...")
        await generate_audio(full_chinese_text, VOICE_CN, SPEECH_RATE_CN, OUTPUT_AUDIO_FILE_CN)

        print("æ’­æ”¾è‹±æ–‡éŸ³é¢‘...")
        play_audio(OUTPUT_AUDIO_FILE_EN)

        print("æ’­æ”¾ä¸­æ–‡éŸ³é¢‘...")
        play_audio(OUTPUT_AUDIO_FILE_CN)

        time.sleep(1)

    print("\nğŸ‰ æ‰€æœ‰å•è¯æ’­æ”¾å®Œæ¯•ï¼")

if __name__ == "__main__":
    asyncio.run(main())

